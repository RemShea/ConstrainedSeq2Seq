{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seq2Seq Model for Text Simplification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "In this notebook, I will walk through the process of training a Bi-directional Seq2Seq model w/ attention mechanism for text simplification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Import & Configure\n",
    "There are quite a few libraries used here. Mainly we rely on keras, and will limit use of other non-standard libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 490,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import regex as re\n",
    "\n",
    "import string\n",
    "import pickle\n",
    "import operator\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input, LSTM, Embedding, Dense, RepeatVector\n",
    "from keras.layers import GRU, TimeDistributed, Bidirectional, merge\n",
    "from keras.models import Model\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.preprocessing.text import one_hot, Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint, TensorBoard\n",
    "from keras.utils import plot_model, np_utils\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define some hyperparameters in processing our variables here, such as the number of samples we want held back for validation and testing, as well as the dimensionality of our embedded vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 377,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "num_train_samples = 100_000\n",
    "num_val_samples = 10_000\n",
    "embedding_dim = 100\n",
    "learning_rate = 0.01\n",
    "n_units = 128\n",
    "vocab_size = 30_000\n",
    "batch_size = 64\n",
    "epochs = 100\n",
    "max_seq_len = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We read in the data below and get a quick look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cherokee, Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>It is the county seat of Alfalfa County .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cherokee, Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>Cherokee is a city in Alfalfa County , Oklahom...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>5</td>\n",
       "      <td>Skateboard decks are usually between 28 and 33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>5</td>\n",
       "      <td>The underside of the deck can be printed with ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>6</td>\n",
       "      <td>This was created by two surfers ; Ben Whatson ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0  1                                                  2\n",
       "0  Cherokee, Oklahoma  0          It is the county seat of Alfalfa County .\n",
       "1  Cherokee, Oklahoma  0  Cherokee is a city in Alfalfa County , Oklahom...\n",
       "2          Skateboard  5  Skateboard decks are usually between 28 and 33...\n",
       "3          Skateboard  5  The underside of the deck can be printed with ...\n",
       "4          Skateboard  6  This was created by two surfers ; Ben Whatson ..."
      ]
     },
     "execution_count": 378,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "normal = pd.read_csv('../data/sentence-aligned.v2/normal.aligned',sep='\\t',header=None)\n",
    "normal.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 379,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cherokee, Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>It is the county seat of Alfalfa County .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cherokee, Oklahoma</td>\n",
       "      <td>0</td>\n",
       "      <td>Cherokee is a city of Oklahoma in the United S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>2</td>\n",
       "      <td>Skateboard decks are normally between 28 and 3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>2</td>\n",
       "      <td>The bottom of the deck can be printed with a d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Skateboard</td>\n",
       "      <td>3</td>\n",
       "      <td>The longboard was made by two surfers ; Ben Wh...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    0  1                                                  2\n",
       "0  Cherokee, Oklahoma  0          It is the county seat of Alfalfa County .\n",
       "1  Cherokee, Oklahoma  0  Cherokee is a city of Oklahoma in the United S...\n",
       "2          Skateboard  2  Skateboard decks are normally between 28 and 3...\n",
       "3          Skateboard  2  The bottom of the deck can be printed with a d...\n",
       "4          Skateboard  3  The longboard was made by two surfers ; Ben Wh..."
      ]
     },
     "execution_count": 379,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simple = pd.read_csv('../data/sentence-aligned.v2/simple.aligned',sep='\\t',header=None)\n",
    "simple.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Text preprocessing\n",
    "The idea here is to get the text into a format usable by our neural networks, and generally tidying up a bit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. pairs before preprocessing: 167689\n",
      "No. pairs after preprocessing: 117952\n"
     ]
    }
   ],
   "source": [
    "# Remove instances where Simple Wikipedia and Wikipedia sentences are identical.\n",
    "identical_filter = (normal[2] != simple[2])\n",
    "\n",
    "# Define a regex pattern used to remove some wikipeida formatting artefacts.\n",
    "# pattern = r'(-lrb-)(?<=-lrb-)(.*?)(?=-rrb-)(-rrb-)'\n",
    "pattern = '-lrb-.*?-rrb-'\n",
    "\n",
    "# Select the column of the 'normal' dataframe with the relevant data.\n",
    "normal_sentences = normal[2][identical_filter]\n",
    "\n",
    "# For each sentence, we want to try to remove string artefacts from wikipedia, usually as a result of hyperlinks\n",
    "# These can greatly increase the size of our sequences, needlessly, and are also noise.\n",
    "input_texts=[]\n",
    "input_vocab=set()\n",
    "for text in normal_sentences:\n",
    "    text = text.lower()\n",
    "    matches = re.findall(pattern,text)\n",
    "    for match in matches:\n",
    "        match = \"\".join(match)\n",
    "        text = text.replace(match,\"\")\n",
    "    sentence = f'{text}'.split(' ')\n",
    "    input_texts.append(sentence)\n",
    "    \n",
    "    # Add unique words to vocabulary\n",
    "    for word in sentence:\n",
    "        if word not in input_vocab:\n",
    "            input_vocab.add(word)\n",
    "\n",
    "\n",
    "# Define beginning of sentence and end of sentence tokens.\n",
    "# These will allow us to initialize our decoder layer and also allow it to know when to stop.\n",
    "bos='bos '\n",
    "eos=' eos'\n",
    "\n",
    "# Do the same for sentences from simplified wikipedia.\n",
    "simplified_sentences = simple[2][identical_filter]\n",
    "target_texts=[]\n",
    "target_vocab=set()\n",
    "for text in normal_sentences:\n",
    "    text = text.lower()\n",
    "    matches = re.findall(pattern,text)\n",
    "    for match in matches:\n",
    "        match = \"\".join(match)\n",
    "        text = text.replace(match,\"\")\n",
    "    sentence = f'{bos}{text}{eos}'.split(' ')\n",
    "    target_texts.append(sentence)\n",
    "    for word in sentence:\n",
    "        if word not in target_vocab:\n",
    "            target_vocab.add(word)\n",
    "    \n",
    "print(f'No. pairs before preprocessing: {len(normal[2])}')\n",
    "print(f'No. pairs after preprocessing: {len(input_texts)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the longest sentence we have in our database. That's pretty dang long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"asiatic cheetah  has for a long time been theoretically classified as a sub-species of the cheetah with the suffix `` venaticus '' applied at the end of its scientific binomial name acinonyx jubatus but at a cheetah reintroduction workshop organized in india on 9 september 2009 stephen j. o'brien from laboratory of genomic diversity of national cancer institute , usa who has in the past conducted numerous prestigious genetic studies including those on asiatic lions said that according to latest modern genetic studies which became possible only now it was discovered that in fact asiatic cheetah was genetically identical to the african cheetah with which it had separated only about 5000 years ago which was not enough time for a sub-species level differentiation , in comparison he said that the asian and african lion subspecies were separated some 100,000 years ago , so was the african and asian leopard subspecies 169,000 years ago . cheetah expert laurie marker of the cheetah conservation fund  and other wildlife experts assembled for the occasion advised the indian government that for reintroduction purposes india should source the cheetah from africa where they were much more numerous instead of trying to have some removed from the critically endangered low population of about worlds last 70 to 100 or so asiatic cheetahs left in iran .\""
      ]
     },
     "execution_count": 381,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "seqs = [len(seq) for seq in input_texts]\n",
    "\" \".join(input_texts[seqs.index(max(seqs))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save Cleaned Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_train,input_test,target_train,target_test = train_test_split(input_texts,target_texts,random_state=42,test_size=validation_split,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Tokenizing\n",
    "Tokenizing is the process of representing words with integers indicating their position in a vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Longest input sequence length: 222\n",
      "Longest target sequence length: 224\n"
     ]
    }
   ],
   "source": [
    "# Instantiate a tokenizer, and determine the size of the vocabulary for our data.\n",
    "# Words outside of our vocabular are replaced by the token 'unk', referring to unkown.\n",
    "tokenizer = Tokenizer(num_words=vocab_size,oov_token='unk')\n",
    "tokenizer.fit_on_texts(input_texts)\n",
    "vocabulary = tokenizer.word_index\n",
    "\n",
    "# Convert the sentences into sequences of integers representing the location of the words in the vocabulary\n",
    "input_integer_sequences = tokenizer.texts_to_sequences(input_texts)\n",
    "target_integer_sequences = tokenizer.texts_to_sequences(target_texts)\n",
    "input_len_seqs = [len(seq) for seq in input_integer_sequences]\n",
    "target_len_seqs = [len(seq) for seq in target_integer_sequences]\n",
    "\n",
    "max_input_seq_len = max(input_len_seqs)\n",
    "print(f'Longest input sequence length: {max_input_seq_len}')\n",
    "max_target_seq_len = max(target_len_seqs)\n",
    "print(f'Longest target sequence length: {max_target_seq_len}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "222 and 224 is quite long; the sentence earlier regarding asiatic cheetahs, although interesting, is not the norm. Let's take a look at the distribution of the lengths of our sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We take the mean plus two standard deviations of our sentence length\n",
    "max_seq_len = np.mean(input_len_seqs) + 2 * np.std(input_len_seqs)\n",
    "max_seq_len = int(max_seq_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average regular wikipedia sentence length:\n",
      "25.7 tokens\n",
      "Average simplified wikipedia sentence length:\n",
      "27.7 tokens\n",
      "Number of regular wikipedia sentences longer than 52 tokens:\n",
      "5696, or 4.83%\n",
      "Number of simplified wikipedia sentences longer than 52 tokens:\n",
      "6718, or 5.7%\n"
     ]
    }
   ],
   "source": [
    "# Choose a cutoff length for our data. This is mainly to prevent the burden on my computer form being unbearable\n",
    "in_above=len([seq for seq in input_len_seqs if seq>=max_seq_len])\n",
    "tar_above=len([seq for seq in target_len_seqs if seq>=max_seq_len])\n",
    "\n",
    "print(f'Average regular wikipedia sentence length:\\n{round(np.mean(input_len_seqs),1)} tokens')\n",
    "print(f'Average simplified wikipedia sentence length:\\n{round(np.mean(target_len_seqs),1)} tokens')\n",
    "print(f'Number of regular wikipedia sentences longer than {max_seq_len} tokens:\\n{in_above}, or {round(100*in_above/len(input_texts),2)}%')\n",
    "print(f'Number of simplified wikipedia sentences longer than {max_seq_len} tokens:\\n{tar_above}, or {round(100*tar_above/len(input_texts),2)}%')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a64e5bc50>"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x576 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(10,8))\n",
    "plt.title(\"Sentence Length\")\n",
    "plt.xlabel(\"Number of words\")\n",
    "plt.axvline(max_seq_len,color='r')\n",
    "sns.distplot(input_len_seqs,color='skyblue',label=\"Wikipedia\")\n",
    "sns.distplot(target_len_seqs,color='firebrick',label=\"Simplified Wikipedia\")\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this step we pad shorter sequences to be 52 tokens long\n",
    "# We also truncate longer sequences to fit the format\n",
    "\n",
    "input_integer_sequences = pad_sequences(\n",
    "    input_integer_sequences,\n",
    "    value=0,\n",
    "    maxlen=max_seq_len,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")\n",
    "target_integer_sequences = pad_sequences(\n",
    "    target_integer_sequences,\n",
    "    value=0,\n",
    "    maxlen=max_seq_len,\n",
    "    padding='post',\n",
    "    truncating='post'\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Embedding\n",
    "The purpose of embedding is to try and find a lower dimension representation of each of the words in our corpus. We can train our own, or we can use pre-trained vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = dict()\n",
    "f = open('../data/glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_dict[word] = coefs\n",
    "f.close()\n",
    "print(f'Loaded {len(embeddings_dict)} word vectors')\n",
    "embedding_matrix = np.zeros((vocab_size,100))\n",
    "for word,i in vocabulary.items():\n",
    "    if i > vocab_size-1:\n",
    "        continue\n",
    "    embedding_vector = embeddings_dict.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 374,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.66432 ,  0.012997,  0.01181 , -0.084488, -0.78247 ,  1.1457  ,\n",
       "        0.25839 , -0.6626  , -1.1347  , -0.83052 ,  1.4438  , -0.17832 ,\n",
       "        0.52204 ,  0.087625,  0.098307, -0.70804 ,  0.058561,  0.40312 ,\n",
       "        0.72853 ,  0.15914 ,  0.0672  ,  0.016688, -0.52523 ,  0.85851 ,\n",
       "        0.85145 , -0.11051 ,  1.0307  , -0.17542 , -0.2927  , -0.59956 ,\n",
       "       -0.24308 ,  1.2302  , -0.81797 ,  0.46934 ,  0.20564 , -0.25792 ,\n",
       "        0.77917 , -0.60109 ,  1.4014  , -0.5972  , -0.40991 ,  0.38727 ,\n",
       "        0.027353, -0.054872, -0.17931 , -0.99247 ,  0.27762 , -0.20651 ,\n",
       "       -0.72933 ,  0.35249 , -0.089301,  0.81046 ,  0.95734 , -0.49469 ,\n",
       "       -0.41374 ,  0.71049 , -0.8651  ,  1.2328  ,  0.14062 , -1.0762  ,\n",
       "        0.45116 ,  0.20948 , -0.49114 , -0.091184, -1.1643  ,  0.3087  ,\n",
       "       -0.78891 , -0.50382 , -0.089517,  0.44128 ,  0.83588 , -0.089127,\n",
       "        0.31822 , -0.59513 , -0.28502 , -1.7288  , -0.69524 , -0.023866,\n",
       "       -0.7321  , -0.5406  ,  0.081562,  0.063065,  1.4587  , -0.017455,\n",
       "        0.11111 ,  0.71711 ,  0.21097 , -0.22816 ,  0.57031 ,  1.2428  ,\n",
       "        0.34171 ,  0.31544 ,  0.18129 ,  0.15407 , -0.094941,  0.049125,\n",
       "        0.68225 , -0.14102 ,  1.2634  , -0.44775 ], dtype=float32)"
      ]
     },
     "execution_count": 374,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_dict['eos']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Batching & Model Building\n",
    "Since I'm handling this data on an old 2013 MacBook Pro, I have to maintain relatively small batch sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = input_integer_sequences[:100_000]\n",
    "train_target = target_integer_sequences[:100_000]\n",
    "\n",
    "test_input = input_integer_sequences[100_001:110_000]\n",
    "test_target = target_integer_sequences[100_001:110_000]\n",
    "\n",
    "batch_indices = range(0,100_000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "dictionary = zip(vocabulary.values(),vocabulary.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functional Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for batch_idx in batch_indices[0:1]:\n",
    "    input_seqs = input_integer_sequences[batch_idx:(batch_idx+100)]\n",
    "    target_seqs = target_integer_sequences[batch_idx:(batch_idx+100)]\n",
    "    encoder_input = np.zeros(\n",
    "        (len(input_seqs),max_seq_len,vocab_size),\n",
    "        dtype='float32'\n",
    "    )\n",
    "    decoder_input = np.zeros(\n",
    "        (len(input_seqs),max_seq_len,vocab_size),\n",
    "        dtype='float32'\n",
    "    )\n",
    "    decoder_target = np.zeros(\n",
    "        (len(input_seqs),max_seq_len,vocab_size),\n",
    "        dtype='int32'\n",
    "    )\n",
    "    for i, (input_seq, target_seq) in enumerate(zip(input_seqs,target_seqs)):\n",
    "        for t, w in enumerate(input_seq):\n",
    "            encoder_input[i, t, w] = 1.\n",
    "        for t, w in enumerate(target_seq):\n",
    "            # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "            decoder_input[i, t, w] = 1.\n",
    "            if t > 0:\n",
    "                # decoder_target_data will be ahead by one timestep\n",
    "                # and will not include the start character.\n",
    "                decoder_target[i, t - 1, w] = 1.\n",
    "    # define training encoder\n",
    "    encoder_inputs = Input(shape=(None, embedding_dim))\n",
    "    encoder = LSTM(n_units, return_state=True) # Bidirectional here\n",
    "    encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "    encoder_states = [state_h, state_c]\n",
    "    # define training decoder\n",
    "    decoder_inputs = Input(shape=(None, embedding_dim))\n",
    "    decoder_lstm = LSTM(n_units, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_inputs, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(embedding_dim, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# decoder_target_data = np.zeros(\n",
    "#     (batch_size,max_seq_len,vocab_size)\n",
    "# )\n",
    "# for i, seqs in enumerate():\n",
    "#     for j,seq in enumerate(seqs):\n",
    "#         if j>0: # Input is ahead of target by one timestep.\n",
    "#             decoder_target_data[i][j][seq] = 1\n",
    "\n",
    "# # The input to the decoder is one word removed from the target of the decoder\n",
    "# encoder_input_data = np.zeros(\n",
    "#     (len(input_texts),max_seq_len),\n",
    "#     dtype='float32'\n",
    "# )\n",
    "# decoder_input_data = np.zeros(\n",
    "#     (len(target_texts),max_seq_len),\n",
    "#     dtype='float32'\n",
    "# )\n",
    "# decoder_target_data = np.zeros(\n",
    "#     (len(target_texts),max_seq_len,vocab_size)\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential??"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate=1e-3\n",
    "model = Sequential()\n",
    "model.add(Bidirectional(GRU(128,input_shape=(max_encoder_seq_length,),return_sequences=False)))\n",
    "model.add(RepeatVector(max_decoder_length))\n",
    "model.add(Bidirectional(GRU(128,return_sequences=True)))\n",
    "model.add(TimeDistributed(Dense(len(target_words),activation='softmax')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratchpad Below This"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 382,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A wrapper for keras' tokenizer class which provides some much needed functionality.\n",
    "# Code from https://github.com/Hvass-Labs/TensorFlow-Tutorials/blob/master/21_Machine_Translation.ipynb\n",
    "class TokenizerWrap(Tokenizer):\n",
    "    \"\"\"Wrap the Tokenizer-class from Keras with more functionality.\"\"\"\n",
    "    def __init__(self, texts, padding,\n",
    "                 reverse=False, num_words=None,oov_token=None):\n",
    "        \"\"\"\n",
    "        :param texts: List of strings. This is the data-set.\n",
    "        :param padding: Either 'post' or 'pre' padding.\n",
    "        :param reverse: Boolean whether to reverse token-lists.\n",
    "        :param num_words: Max number of words to use.\n",
    "        \"\"\"\n",
    "        Tokenizer.__init__(self, num_words=num_words,oov_token=oov_token)\n",
    "        self.fit_on_texts(texts)\n",
    "        self.index_to_word = dict(zip(self.word_index.values(),\n",
    "                                      self.word_index.keys()))\n",
    "        self.tokens = self.texts_to_sequences(texts)\n",
    "        if reverse:\n",
    "            self.tokens = [list(reversed(x)) for x in self.tokens]\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            truncating = 'post'\n",
    "        self.num_tokens = [len(x) for x in self.tokens]\n",
    "        self.max_tokens = np.mean(self.num_tokens) \\\n",
    "                          + 2 * np.std(self.num_tokens)\n",
    "        self.max_tokens = int(self.max_tokens)\n",
    "        self.tokens_padded = pad_sequences(self.tokens,\n",
    "                                           maxlen=self.max_tokens,\n",
    "                                           padding=padding,\n",
    "                                           truncating=truncating)\n",
    "    def token_to_word(self, token):\n",
    "        \"\"\"Lookup a single word from an integer-token.\"\"\"\n",
    "        word = \" \" if token == 0 else self.index_to_word[token]\n",
    "        return word \n",
    "    def tokens_to_string(self, tokens):\n",
    "        \"\"\"Convert a list of integer-tokens to a string.\"\"\"\n",
    "        words = [self.index_to_word[token]\n",
    "                 for token in tokens\n",
    "                 if token != 0]\n",
    "        text = \" \".join(words)\n",
    "        return text\n",
    "    def text_to_tokens(self, text, reverse=False, padding=False):\n",
    "        \"\"\"\n",
    "        Convert a single text-string to tokens with optional\n",
    "        reversal and padding.\n",
    "        \"\"\"\n",
    "        tokens = self.texts_to_sequences([text])\n",
    "        tokens = np.array(tokens)\n",
    "        if reverse:\n",
    "            tokens = np.flip(tokens, axis=1)\n",
    "            truncating = 'pre'\n",
    "        else:\n",
    "            truncating = 'post'\n",
    "        if padding:\n",
    "            tokens = pad_sequences(tokens,maxlen=self.max_tokens,\n",
    "                                   padding='pre',\n",
    "                                   truncating=truncating)\n",
    "        return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.9 s, sys: 164 ms, total: 6.06 s\n",
      "Wall time: 6.13 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "input_tokenizer = TokenizerWrap(texts=input_texts,\n",
    "                                padding='pre',\n",
    "                                reverse=True,\n",
    "                                num_words=vocab_size,\n",
    "                                oov_token='unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tokenized = input_tokenizer.tokens_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117952, 52)"
      ]
     },
     "execution_count": 385,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_tokenizer = TokenizerWrap(texts=target_texts,\n",
    "                                padding='post',\n",
    "                                reverse=False,\n",
    "                                num_words=vocab_size,\n",
    "                                oov_token='unk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets_tokenized = target_tokenizer.tokens_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117952, 54)"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets_tokenized.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input_data = inputs_tokenized\n",
    "decoder_input_data = targets_tokenized[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117952, 53)"
      ]
     },
     "execution_count": 390,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_input_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(117952, 53)"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output_data = targets_tokenized[:,1:]\n",
    "decoder_output_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 392,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400001 word vectors\n"
     ]
    }
   ],
   "source": [
    "embeddings_dict = {}\n",
    "f = open('../data/glove.6B/glove.6B.100d.txt')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:],dtype='float32')\n",
    "    embeddings_dict[word] = coefs\n",
    "f.close()\n",
    "print(f'Loaded {len(embeddings_dict)} word vectors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "input_embed_matrix = np.zeros((vocab_size,embedding_dim))\n",
    "for word, i in input_tokenizer.word_index.items():\n",
    "    if i >= vocab_size:\n",
    "        continue\n",
    "    vec = embeddings_dict.get(word)\n",
    "    if vec is not None:\n",
    "        input_embed_matrix[i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_embed_matrix = np.zeros((vocab_size,embedding_dim))\n",
    "for word, i in target_tokenizer.word_index.items():\n",
    "    if i >= vocab_size:\n",
    "        continue\n",
    "    vec = embeddings_dict.get(word)\n",
    "    if vec is not None:\n",
    "        target_embed_matrix[i] = vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 480,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder_input = Input(shape=(None,),name='encoder_input')\n",
    "encoder_embedding = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = embedding_dim,\n",
    "    embeddings_initializer=Constant(input_embed_matrix),\n",
    "    trainable = False,\n",
    "    name='encoder_embedding')\n",
    "# encoder_birnn = Bidirectional(GRU(units=n_units,return_sequences=True))\n",
    "encoder_birnn = GRU(units=n_units,return_sequences=True)\n",
    "\n",
    "\n",
    "def connect_encoder():\n",
    "    net = encoder_input\n",
    "    net = encoder_embedding(net)\n",
    "    net = encoder_birnn(net)\n",
    "    encoder_output = net\n",
    "    return encoder_output\n",
    "\n",
    "# encoder_output = encoder_birnn(encoder_embedding(encoder_input))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoder_output = connect_encoder()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_initial_state = Input(shape=(n_units,),name='decoder_initial_state')\n",
    "decoder_input = Input(shape=(None,),name='decoder_input')\n",
    "decoder_embedding = Embedding(\n",
    "    input_dim = vocab_size,\n",
    "    output_dim = embedding_dim,\n",
    "    embeddings_initializer=Constant(target_embed_matrix),\n",
    "    trainable = False,\n",
    "    name='decoder_embedding')\n",
    "decoder_rnn = GRU(units=n_units,return_sequences=True)\n",
    "decoder_dense = Dense(vocab_size,activation='linear',name='decoder_output')\n",
    "\n",
    "def connect_decoder(initial_state):\n",
    "    net = decoder_input\n",
    "    net = decoder_embedding(net)\n",
    "    net = decoder_rnn(net,initial_state=initial_state)\n",
    "    decoder_output = decoder_dense(net)\n",
    "    return decoder_output\n",
    "\n",
    "# decoder_output = decoder_dense(decoder_rnn(decoder_embedding(decoder_input),initial_state=encoder_output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder_output = connect_decoder(initial_state=encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 484,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_train = Model(inputs=[encoder_input,decoder_input],\n",
    "                    outputs=[decoder_output])\n",
    "\n",
    "model_encoder = Model(inputs=[encoder_input],\n",
    "                      outputs=[encoder_output])\n",
    "decoder_output = connect_decoder(initial_state = decoder_initial_state)\n",
    "model_decoder = Model(inputs=[decoder_input,decoder_initial_state],\n",
    "                      outputs=[decoder_output])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "encoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "decoder_input (InputLayer)      (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "encoder_embedding (Embedding)   (None, None, 100)    3000000     encoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "decoder_embedding (Embedding)   (None, None, 100)    3000000     decoder_input[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "gru_32 (GRU)                    (None, None, 128)    87936       encoder_embedding[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "gru_33 (GRU)                    (None, None, 128)    87936       decoder_embedding[0][0]          \n",
      "                                                                 gru_32[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "decoder_output (Dense)          (None, None, 30000)  3870000     gru_33[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 10,045,872\n",
      "Trainable params: 4,045,872\n",
      "Non-trainable params: 6,000,000\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 469,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 488,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "decoder_target = tf.placeholder(dtype='float32', shape=(None, None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 489,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Input 'y' of 'Equal' Op has type float32 that does not match type int32 of argument 'x'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    510\u001b[0m                 \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minput_arg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_ref\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 511\u001b[0;31m                 preferred_dtype=default_dtype)\n\u001b[0m\u001b[1;32m    512\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mTypeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36minternal_convert_to_tensor\u001b[0;34m(value, dtype, name, as_ref, preferred_dtype, ctx, accept_symbolic_tensors)\u001b[0m\n\u001b[1;32m   1174\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mret\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1175\u001b[0;31m       \u001b[0mret\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconversion_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mas_ref\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mas_ref\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m_TensorTensorConversionFunction\u001b[0;34m(t, dtype, name, as_ref)\u001b[0m\n\u001b[1;32m    976\u001b[0m         \u001b[0;34m\"Tensor conversion requested dtype %s for Tensor with dtype %s: %r\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m         (dtype.name, t.dtype.name, str(t)))\n\u001b[0m\u001b[1;32m    978\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Tensor conversion requested dtype int32 for Tensor with dtype float32: 'Tensor(\"metrics_7/acc/Round:0\", shape=(?, 100, 1), dtype=float32)'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-489-3f3f9db398b4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m               \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msparse_cross_entropy\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m               \u001b[0mtarget_tensors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mdecoder_target\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m               metrics=['acc'])\n\u001b[0m",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mcompile\u001b[0;34m(self, optimizer, loss, metrics, loss_weights, sample_weight_mode, weighted_metrics, target_tensors, **kwargs)\u001b[0m\n\u001b[1;32m    449\u001b[0m                 \u001b[0moutput_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    450\u001b[0m                 \u001b[0moutput_weighted_metrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnested_weighted_metrics\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 451\u001b[0;31m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_metrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    452\u001b[0m                 \u001b[0mhandle_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_weighted_metrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    453\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mhandle_metrics\u001b[0;34m(metrics, weights)\u001b[0m\n\u001b[1;32m    418\u001b[0m                     metric_result = weighted_metric_fn(y_true, y_pred,\n\u001b[1;32m    419\u001b[0m                                                        \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mweights\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 420\u001b[0;31m                                                        mask=masks[i])\n\u001b[0m\u001b[1;32m    421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    422\u001b[0m                 \u001b[0;31m# Append to self.metrics_names, self.metric_tensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mweighted\u001b[0;34m(y_true, y_pred, weights, mask)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \"\"\"\n\u001b[1;32m    403\u001b[0m         \u001b[0;31m# score_array has ndim >= 2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 404\u001b[0;31m         \u001b[0mscore_array\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    405\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmask\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m             \u001b[0;31m# Cast the mask to floatX to avoid float64 upcasting in Theano\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/metrics.py\u001b[0m in \u001b[0;36mbinary_accuracy\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mbinary_accuracy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mround\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m   1614\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mbool\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1615\u001b[0m     \"\"\"\n\u001b[0;32m-> 1616\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mequal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1617\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/ops/gen_math_ops.py\u001b[0m in \u001b[0;36mequal\u001b[0;34m(x, y, name)\u001b[0m\n\u001b[1;32m   3092\u001b[0m   \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3093\u001b[0m     _, _, _op = _op_def_lib._apply_op_helper(\n\u001b[0;32m-> 3094\u001b[0;31m         \"Equal\", x=x, y=y, name=name)\n\u001b[0m\u001b[1;32m   3095\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mTypeError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3096\u001b[0m     result = _dispatch.dispatch(\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/tensorflow/python/framework/op_def_library.py\u001b[0m in \u001b[0;36m_apply_op_helper\u001b[0;34m(self, op_type_name, name, **keywords)\u001b[0m\n\u001b[1;32m    545\u001b[0m                   \u001b[0;34m\"%s type %s of argument '%s'.\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    546\u001b[0m                   (prefix, dtypes.as_dtype(attrs[input_arg.type_attr]).name,\n\u001b[0;32m--> 547\u001b[0;31m                    inferred_from[input_arg.type_attr]))\n\u001b[0m\u001b[1;32m    548\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m           \u001b[0mtypes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: Input 'y' of 'Equal' Op has type float32 that does not match type int32 of argument 'x'."
     ]
    }
   ],
   "source": [
    "model.compile(optimizer='rmsprop',\n",
    "              loss=sparse_cross_entropy,\n",
    "              target_tensors=[decoder_target],\n",
    "              metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 472,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_checkpoint = 'capstone_checkpoint.keras'\n",
    "callback_checkpoint = ModelCheckpoint(filepath=path_checkpoint,\n",
    "                                      monitor='val_loss',\n",
    "                                      verbose=1,\n",
    "                                      save_weights_only=True,\n",
    "                                      save_best_only=True)\n",
    "callback_early_stopping = EarlyStopping(monitor='val_loss',\n",
    "                                        patience=3, verbose=1)\n",
    "callback_tensorboard = TensorBoard(log_dir='./capstone_logs/',\n",
    "                                   histogram_freq=0,\n",
    "                                   write_graph=False)\n",
    "\n",
    "callbacks = [callback_early_stopping,\n",
    "             callback_checkpoint,\n",
    "             callback_tensorboard]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 473,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error trying to load checkpoint.\n",
      "Unable to open file (unable to open file: name = 'capstone_checkpoint.keras', errno = 2, error message = 'No such file or directory', flags = 0, o_flags = 0)\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    model_train.load_weights(path_checkpoint)\n",
    "except Exception as error:\n",
    "    print(\"Error trying to load checkpoint.\")\n",
    "    print(error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = \\\n",
    "{\n",
    "    'encoder_input': encoder_input_data,\n",
    "    'decoder_input': decoder_input_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 475,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_data = \\\n",
    "{\n",
    "    'decoder_output': decoder_output_data\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 476,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_split = 10000/len(encoder_input_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 477,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0847802495930548"
      ]
     },
     "execution_count": 477,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validation_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[    0,     0,     0, ...,     8,     9,  7190],\n       [    0,     0,     0, ...,    26, 22331, 22330],\n       [    0,     0,     0, ...,     5,  7359,     2],\n       ...,\n       [    0,     ...",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-478-4853af253f23>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_split\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m             \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m             batch_size=batch_size)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;31m# Prepare validation data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m         \u001b[0mdo_validation\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Applications/anaconda3/lib/python3.7/site-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    100\u001b[0m                 \u001b[0;34m'Expected to see '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' array(s), '\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m                 \u001b[0;34m'but instead got the following list of '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m                 str(len(data)) + ' arrays: ' + str(data)[:200] + '...')\n\u001b[0m\u001b[1;32m    103\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnames\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m             raise ValueError(\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking model input: the list of Numpy arrays that you are passing to your model is not the size the model expected. Expected to see 1 array(s), but instead got the following list of 2 arrays: [array([[    0,     0,     0, ...,     8,     9,  7190],\n       [    0,     0,     0, ...,    26, 22331, 22330],\n       [    0,     0,     0, ...,     5,  7359,     2],\n       ...,\n       [    0,     ..."
     ]
    }
   ],
   "source": [
    "model.fit(\n",
    "    x=[encoder_input_data,decoder_input_data],\n",
    "    y=[decoder_output_data],\n",
    "    batch_size=64,\n",
    "    epochs=2,\n",
    "    callbacks=callbacks,\n",
    "    validation_split=validation_split\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_input = input_integer_sequences[:100_000]\n",
    "train_target = target_integer_sequences[:100_000]\n",
    "\n",
    "test_input = input_integer_sequences[100_001:110_000]\n",
    "test_target = target_integer_sequences[100_001:110_000]\n",
    "\n",
    "batch_indices = range(0,100_000,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-495-2a79a417f827>, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-495-2a79a417f827>\"\u001b[0;36m, line \u001b[0;32m6\u001b[0m\n\u001b[0;31m    batch_size=,\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "for batch_idx in batch_indices[0:1]:\n",
    "    train_encoder_input = np.array(train_encoder_input_data[batch_idx:(batch_idx+100)])\n",
    "    train_decoder_input = np.array(train_decoder_input_data[batch_idx:(batch_idx+100)])\n",
    "    train_decoder_output= np.array(train_decoder_output_data[batch_idx:(batch_idx+100)])\n",
    "    model.fit([train_encoder_input, train_decoder_input], train_decoder_target,\n",
    "          batch_size=,\n",
    "          epochs=epochs,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'decoder_target_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-338-7d0fdb52c39a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m model.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n\u001b[0m\u001b[1;32m      2\u001b[0m           \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m           \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m           validation_split=0.20)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'decoder_target_data' is not defined"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
