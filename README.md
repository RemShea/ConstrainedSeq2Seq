
This is the start of a personal project I'd been working on circa June of 2019. The idea initially came during my search for a capstone project for my General Assembly Data Science Immersive program.
The idea was to train a sequence-to-sequence neural network to simplify English text, using a parallel corpus of wikipedia entries in the regular English Wikipedia language and it's corresponding 'Simple English' page.
The project ultimately proved to be beyond the scope of what was possible in the two weeks I had for the capstone, so I abandoned it in favor of a cluster analysis of NBA players.
I do think the idea still has legs, and intend to one day resurrect it. I find the idea intriguing because the input and output of the neural network are so similar yet notably different, so the neural network would have to have understood something about the essence of text; what is superfluous information and what is essential.
This could impact things like tailoring communication of topics to different levels of English proficiency, perhaps most directly to assist in those trying to understand complicated topics in simpler terms. Almost something like an ELI5-bot.
